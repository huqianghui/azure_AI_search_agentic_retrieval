{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92776caa",
   "metadata": {},
   "source": [
    "# 4 - Maximize relevance\n",
    "\n",
    "Azure AI Search provides relevance tuning strategies for improving the relevance of search results in classic RAG solutions.  Relevance tuning can be an important factor in delivering a RAG solution that meets user expectations. \n",
    "\n",
    "In Azure AI Search, relevance tuning includes L2 semantic ranking and scoring profiles. To implement these capabilities, you revisit the index schema to add configurations for semantic ranking and scoring profiles. You then rerun the queries using the new constructs.\n",
    "\n",
    "In this example, you modify the existing search index and queries to use:\n",
    "\n",
    "- L2 semantic ranking\n",
    "- Scoring profile for document boosting\n",
    "\n",
    "This example updates the search index created by the [indexing pipeline](2-build-the-pipeline.ipynb). Updates don't affect the existing content, so no rebuild is necessary and you don't need to rerun the indexer.\n",
    "\n",
    "## Run a baseline query for comparison\n",
    "\n",
    "Let's start with a new query, \"Are there any cloud formations specific to oceans and large bodies of water?\".\n",
    "\n",
    "To compare outcomes after adding relevance features, run the query against the existing index schema, before you add semantic ranking or a scoring profile.\n",
    "\n",
    "For the Azure Government cloud, modify the API endpoint on the token provider to `\"https://cognitiveservices.azure.us/.default\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348578e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "openai_client = AzureOpenAI(\n",
    "     api_version=\"2024-06-01\",\n",
    "     azure_endpoint=AZURE_OPENAI_ACCOUNT,\n",
    "     azure_ad_token_provider=token_provider\n",
    " )\n",
    "\n",
    "deployment_name = \"gpt-4o\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "     endpoint=AZURE_SEARCH_SERVICE,\n",
    "     index_name=index_name,\n",
    "     credential=credential\n",
    " )\n",
    "\n",
    "GROUNDED_PROMPT=\"\"\"\n",
    "You are an AI assistant that helps users learn from the information found in the source material.\n",
    "Answer the query using only the sources provided below.\n",
    "Use bullets if the answer has multiple points.\n",
    "If the answer is longer than 3 sentences, provide a summary.\n",
    "Answer ONLY with the facts listed in the list of sources below. Cite your source when you answer the question\n",
    "If there isn't enough information below, say you don't know.\n",
    "Do not generate answers that don't use the sources below.\n",
    "Query: {query}\n",
    "Sources:\\n{sources}\n",
    "\"\"\"\n",
    "\n",
    "# Focused query on cloud formations and bodies of water\n",
    "query=\"Are there any cloud formations specific to oceans and large bodies of water?\"\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=50, fields=\"text_vector\")\n",
    "\n",
    "search_results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"title\", \"chunk\", \"locations\"],\n",
    "    top=5,\n",
    ")\n",
    "\n",
    "sources_formatted = \"=================\\n\".join([f'TITLE: {document[\"title\"]}, CONTENT: {document[\"chunk\"]}, LOCATIONS: {document[\"locations\"]}' for document in search_results])\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": GROUNDED_PROMPT.format(query=query, sources=sources_formatted)\n",
    "        }\n",
    "    ],\n",
    "    model=deployment_name\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aeaa16",
   "metadata": {},
   "source": [
    "Output from this request might look like the following example.\n",
    "\n",
    "```\n",
    "Yes, there are cloud formations specific to oceans and large bodies of water. \n",
    "A notable example is \"cloud streets,\" which are parallel rows of clouds that form over \n",
    "the Bering Strait in the Arctic Ocean. These cloud streets occur when wind blows from \n",
    "a cold surface like sea ice over warmer, moister air near the open ocean, leading to \n",
    "the formation of spinning air cylinders. Clouds form along the upward cycle of these cylinders, \n",
    "while skies remain clear along the downward cycle (Source: page-21.pdf).\n",
    "```\n",
    "\n",
    "## Update the index for semantic ranking and scoring profiles\n",
    "\n",
    "Azure AI Search has multiple features and capabilities that improve relevance. In this step, we add two of them: semantic ranking and scoring profiles. We purposely omitted relevance enhancements from that schema so that you could focus on the fundamentals. Deferring relevance to a separate exercise gives you a before-and-after comparison of the quality of search results after the updates are made.\n",
    "\n",
    "Semantic ranking and scoring profile configurations exist in the index schema. You can update an existing index to use both without incurring a [rebuild requirement](https://learn.microsoft.com/azure/search/search-howto-reindex). \n",
    "\n",
    "- A [semantic configuration](https://learn.microsoft.com/azure/search/semantic-how-to-configure) has a name and a prioritized list of fields to help optimize the inputs to semantic ranker.\n",
    "\n",
    "- A [scoring profile definition](https://learn.microsoft.com/azure/search/index-add-scoring-profiles) has a name and this one uses the tag function to boost the scores of documents where a match was found in the locations field. Recall that the search index has a vector field, and multiple nonvector fields for title, chunks, and locations. The locations field is a string collection, and string collections can be boosted using the tags function in a scoring profile.\n",
    "\n",
    "An update request should include all of the existing schema definitions that you want to keep, plus the new or changed elements. It's a best practice to issue a GET INDEX request to retrieve the current index before adding new elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd51d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the classes to include the new fields\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.identity import get_bearer_token_provider\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    SearchIndex,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSearch,\n",
    "    ScoringProfile,\n",
    "    TagScoringFunction,\n",
    "    TagScoringParameters\n",
    ")\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Existing index name, client and fields\n",
    "index_name = \"py-rag-tutorial-idx\"\n",
    "index_client = SearchIndexClient(endpoint=AZURE_SEARCH_SERVICE, credential=credential)  \n",
    "fields = [\n",
    "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String),  \n",
    "    SearchField(name=\"title\", type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"locations\", type=SearchFieldDataType.Collection(SearchFieldDataType.String), filterable=True),\n",
    "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True, analyzer_name=\"keyword\"),  \n",
    "    SearchField(name=\"chunk\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),  \n",
    "    SearchField(name=\"text_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=1024, vector_search_profile_name=\"myHnswProfile\")\n",
    "    ]  \n",
    "  \n",
    "# Existing vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(name=\"myHnsw\"),\n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "        )\n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            parameters=AzureOpenAIVectorizerParameters(  \n",
    "                resource_url=AZURE_OPENAI_ACCOUNT,  \n",
    "                deployment_name=\"text-embedding-3-large\",\n",
    "                model_name=\"text-embedding-3-large\"\n",
    "            ),\n",
    "        ),  \n",
    "    ], \n",
    ")\n",
    "\n",
    "# New semantic configuration\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        keywords_fields=[SemanticField(field_name=\"locations\")],\n",
    "        content_fields=[SemanticField(field_name=\"chunk\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# New scoring profile\n",
    "scoring_profiles = [  \n",
    "    ScoringProfile(  \n",
    "        name=\"my-scoring-profile\",\n",
    "        functions=[\n",
    "            TagScoringFunction(  \n",
    "                field_name=\"locations\",  \n",
    "                boost=5.0,  \n",
    "                parameters=TagScoringParameters(  \n",
    "                    tags_parameter=\"tags\",  \n",
    "                ),  \n",
    "            ) \n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "# Update the search index with the semantic configuration and scoring profile\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search, scoring_profiles=scoring_profiles)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} updated\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a134c5",
   "metadata": {},
   "source": [
    "## Update queries for semantic ranking and scoring profiles\n",
    "\n",
    "In a previous example, you [ran queries](3-search-and-generate-answers.ipynb) that execute on the search engine, passing the response and other information to an LLM for chat completion.\n",
    "\n",
    "This example modifies the query request to include the semantic configuration and scoring profile.\n",
    "\n",
    "For the Azure Government cloud, modify the API endpoint on the token provider to `\"https://cognitiveservices.azure.us/.default\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca097db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from azure.search.documents import SearchClient\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "openai_client = AzureOpenAI(\n",
    "     api_version=\"2024-06-01\",\n",
    "     azure_endpoint=AZURE_OPENAI_ACCOUNT,\n",
    "     azure_ad_token_provider=token_provider\n",
    " )\n",
    "\n",
    "deployment_name = \"gpt-4o\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "     endpoint=AZURE_SEARCH_SERVICE,\n",
    "     index_name=index_name,\n",
    "     credential=credential\n",
    " )\n",
    "\n",
    "# Prompt is unchanged in this update\n",
    "GROUNDED_PROMPT=\"\"\"\n",
    "You are an AI assistant that helps users learn from the information found in the source material.\n",
    "Answer the query using only the sources provided below.\n",
    "Use bullets if the answer has multiple points.\n",
    "If the answer is longer than 3 sentences, provide a summary.\n",
    "Answer ONLY with the facts listed in the list of sources below.\n",
    "If there isn't enough information below, say you don't know.\n",
    "Do not generate answers that don't use the sources below.\n",
    "Query: {query}\n",
    "Sources:\\n{sources}\n",
    "\"\"\"\n",
    "\n",
    "# Queries are unchanged in this update\n",
    "query=\"Are there any cloud formations specific to oceans and large bodies of water?\"\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=50, fields=\"text_vector\")\n",
    "\n",
    "# Add query_type semantic and semantic_configuration_name\n",
    "# Add scoring_profile and scoring_parameters\n",
    "search_results = search_client.search(\n",
    "    query_type=\"semantic\",\n",
    "    semantic_configuration_name=\"my-semantic-config\",\n",
    "    scoring_profile=\"my-scoring-profile\",\n",
    "    scoring_parameters=[\"tags-ocean, 'sea surface', seas, surface\"],\n",
    "    search_text=query,\n",
    "    vector_queries= [vector_query],\n",
    "    select=\"title, chunk, locations\",\n",
    "    top=5,\n",
    ")\n",
    "sources_formatted = \"=================\\n\".join([f'TITLE: {document[\"title\"]}, CONTENT: {document[\"chunk\"]}, LOCATIONS: {document[\"locations\"]}' for document in search_results])\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": GROUNDED_PROMPT.format(query=query, sources=sources_formatted)\n",
    "        }\n",
    "    ],\n",
    "    model=deployment_name\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4325ac69",
   "metadata": {},
   "source": [
    "Output from a semantically ranked and boosted query might look like the following example.\n",
    "\n",
    "```\n",
    "Yes, there are specific cloud formations influenced by oceans and large bodies of water:\n",
    "\n",
    "- **Stratus Clouds Over Icebergs**: Low stratus clouds can frame holes over icebergs, \n",
    "such as Iceberg A-56 in the South Atlantic Ocean, likely due to thermal instability caused \n",
    "by the iceberg (source: page-39.pdf).\n",
    "\n",
    "- **Undular Bores**: These are wave structures in the atmosphere created by the collision \n",
    "of cool, dry air from a continent with warm, moist air over the ocean, as seen off the \n",
    "coast of Mauritania (source: page-23.pdf).\n",
    "\n",
    "- **Ship Tracks**: These are narrow clouds formed by water vapor condensing around tiny \n",
    "particles from ship exhaust. They are observed over the oceans, such as in the Pacific Ocean \n",
    "off the coast of California (source: page-31.pdf).\n",
    "\n",
    "These specific formations are influenced by unique interactions between atmospheric conditions \n",
    "and the presence of large water bodies or objects within them.\n",
    "```\n",
    "\n",
    "Adding semantic ranking and scoring profiles positively affects the response from the LLM by promoting results that meet scoring criteria and are semantically relevant. \n",
    "\n",
    "Now that you have a better understanding of index and query design, let's move on to optimizing for speed and concision. We revisit the schema definition to implement quantization and storage reduction, but the rest of the pipeline and models remain intact.\n",
    "\n",
    "<!-- ## Update queries for minimum thresholds ** NOT AVAILABLE IN PYTHON SDK\n",
    "\n",
    "Keyword search only returns results if there's match found in the index, up to a maximum of 50 results by default. In contrast, vector search returns `k`-results every time, even if the matching vectors aren't a close match.\n",
    "\n",
    "In the vector query portion of the request, add a threshold object and set a minimum value for including vector matches in the results.\n",
    "\n",
    "Vector scores range from 0.333 to 1.00. For more information, see [Set thresholds to exclude low-scoring results](vector-search-how-to-query.md#set-thresholds-to-exclude-low-scoring-results-preview) and [Scores in a vector search results](vector-search-ranking.md#scores-in-a-vector-search-results).\n",
    "\n",
    "```python\n",
    "# Update the vector_query to include a minimum threshold.\n",
    "query=\"how much of earth is covered by water\"\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"text_vector\", threshold.kind=\"vectorSImiliarty\", threshold.value=0.8, exhaustive=True) -->\n",
    "\n",
    "<!-- ## Update queries for vector weighting\n",
    "\n",
    "<!-- Using preview features, you can unpack a hybrid search score to review the individual component scores. Based on that information, you can set minimum thresholds to exclude any match that falls below it.\n",
    "\n",
    "Semantic ranking and scoring profiles operate on nonvector content, but you can tune the vector portion of a hybrid query to amplify or diminish its importance based on how much value it adds to the results. For example, if you run keyword search and vector search independently and find that one of them is outperforming the other, you can adjust the weight on the vector side to higher or lower. This approach gives you more control over query processing.\n",
    " -->\n",
    "\n",
    "<!-- Key points:\n",
    "\n",
    "- How to measure relevance (?) to determine if changes are improving results\n",
    "- Try different algorithms (HNSW vs eKnn)\n",
    "- Change query structure (hybrid with vector/non over same content (double-down), hybrid over multiple fields)\n",
    "- semantic ranking\n",
    "- scoring profiles\n",
    "- thresholds for minimum score\n",
    "- set weights\n",
    "- filters\n",
    "- analyzers and normalizers\n",
    "- advanced query formats (regular expressions, fuzzy search) -->"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
